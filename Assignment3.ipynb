{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c3e5e40-3fcb-4a95-986b-3fd4687e2ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.11/site-packages (1.11.3)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/homebrew/lib/python3.11/site-packages (from scipy) (1.26.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.11/site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (0.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (4.43.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in /opt/homebrew/lib/python3.11/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/homebrew/lib/python3.11/site-packages (from seaborn) (1.26.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/homebrew/lib/python3.11/site-packages (from seaborn) (2.1.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in /opt/homebrew/lib/python3.11/site-packages (from seaborn) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.43.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scipy\n",
    "%pip install networkx\n",
    "%pip install matplotlib\n",
    "%pip install pandas\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfd4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc4d613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program may take several minutes to complete. Please wait.\n",
      "Computing Eigenvector Centrality...\n",
      "Computing Degree Centrality...\n",
      "Computing Katz Centrality...\n",
      "Computing PageRank Centrality...\n",
      "Computing Betweenness Centrality...\n"
     ]
    }
   ],
   "source": [
    "###################QUESTION 1a####################################\n",
    "print(\"Program may take several minutes to complete. Please wait.\")\n",
    "edges = pd.read_csv('lastfm_asia_edges.csv')\n",
    "\n",
    "g1 = nx.from_pandas_edgelist(edges, 'node_1', 'node_2')\n",
    "print(\"Computing Eigenvector Centrality...\")\n",
    "eigenvector_centrality = nx.eigenvector_centrality(g1)\n",
    "print(\"Computing Degree Centrality...\")\n",
    "degree_centrality = nx.degree_centrality(g1)\n",
    "try:\n",
    "    print(\"Computing Katz Centrality...\")\n",
    "    katz_centrality = nx.katz_centrality(g1, alpha=0.01)\n",
    "except nx.PowerIterationFailedConvergence:\n",
    "    print(\"Katz centrality could not converge\")\n",
    "print(\"Computing PageRank Centrality...\")\n",
    "pagerank_centrality = nx.pagerank(g1)\n",
    "print(\"Computing Betweenness Centrality...\")\n",
    "betweeness_centrality = nx.betweenness_centrality(g1)\n",
    "print(\"Computing Closeness Centrality...\")\n",
    "closeness_centrality = nx.closeness_centrality(g1)\n",
    "print(\"Eigenvector Centrality:\", eigenvector_centrality)\n",
    "print(\"Degree Centrality: \", degree_centrality)\n",
    "if 'katz_centrality' in locals():\n",
    "    print(\"Katz Centrality:\", katz_centrality)\n",
    "print(\"PageRank Centrality:\", pagerank_centrality)\n",
    "print(\"Betweenness Centrality:\", betweeness_centrality)\n",
    "print(\"Closeness Centrality:\", closeness_centrality)\n",
    "\n",
    "########################QUESTION 1b###############################\n",
    "def calculateCorrelationCoefficents():\n",
    "    dc_list = list(degree_centrality.values())\n",
    "    ev_list = list(eigenvector_centrality.values())\n",
    "    if 'katz_centrality' in locals():\n",
    "        k_list = list(katz_centrality.values())\n",
    "    else:\n",
    "        k_list = None\n",
    "    pr_list = list(pagerank_centrality.values())\n",
    "    b_list = list(betweeness_centrality.values())\n",
    "    c_list = list(closeness_centrality.values())\n",
    "\n",
    "    r_values = []\n",
    "    correlations = [\n",
    "        dc_list,\n",
    "        ev_list,\n",
    "        k_list,\n",
    "        pr_list,\n",
    "        b_list,\n",
    "        c_list\n",
    "    ]\n",
    "    for _, c1 in enumerate(correlations):\n",
    "        row = []\n",
    "        for _, c2 in enumerate(correlations):\n",
    "            if c1 is not None and c2 is not None:\n",
    "                r, _ = pearsonr(c1, c2)\n",
    "                row.append(r)\n",
    "            else:\n",
    "                row.append(None)\n",
    "        r_values.append(row)\n",
    "\n",
    "    print(\"Pearson's r values: \")\n",
    "    for row in r_values:\n",
    "        print(row)\n",
    "\n",
    "calculateCorrelationCoefficents()\n",
    "\n",
    "##########################QUESTION 1c###########################\n",
    "centrality_data = pd.DataFrame({\n",
    "    'Degree Centrality': list(degree_centrality.values()),\n",
    "    'Eigenvector Centrality': list(eigenvector_centrality.values()),\n",
    "    'Katz Centrality': list(katz_centrality.values()) if 'katz_centrality' in locals() else None,\n",
    "    'PageRank Centrality': list(pagerank_centrality.values()),\n",
    "    'Betweenness Centrality': list(betweeness_centrality.values()),\n",
    "    'Closeness Centrality': list(closeness_centrality.values())\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.set(style=\"whitegrid\")\n",
    "sb.ecdfplot(data=centrality_data, marker=\"x\", palette=\"bright\")\n",
    "\n",
    "plt.legend(title='Centrality Measures', loc='lower right', labels=list(centrality_data.columns))\n",
    "plt.xlabel('Centrality Value')\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.ylim(-0.25, 1.25)\n",
    "plt.xlim(-0.1, 0.3)\n",
    "plt.title('Cumulative distribution functions')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849ea757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'v1': [], 'v2': [], 'v3': [], 'v4': [], 'v5': [], 'v6': []}\n",
      "{'v1': ['v3', 'v4'], 'v2': ['v1', 'v5'], 'v3': ['v1', 'v2'], 'v4': ['v3'], 'v5': ['v4', 'v6'], 'v6': ['v2']}\n",
      "PageRank Results:\n",
      "v1: 0.20046031173347453\n",
      "v2: 0.17648393695535605\n",
      "v3: 0.16335010147737383\n",
      "v4: 0.15578531260040415\n",
      "v5: 0.17343073839836537\n",
      "v6: 0.17500187633153952\n",
      "\n",
      "Networkx PageRank Results:\n",
      "v1: 0.21468970874195084\n",
      "v3: 0.2536631864577143\n",
      "v4: 0.16166931067686457\n",
      "v2: 0.19266842589894956\n",
      "v5: 0.10688343909265172\n",
      "v6: 0.07042592913186885\n"
     ]
    }
   ],
   "source": [
    "#######################QUESTION 2#############################\n",
    "nodes = ['v1', 'v2', 'v3', 'v4', 'v5', 'v6']\n",
    "edges = [('v1', 'v3'), ('v3', 'v1'), ('v1', 'v4'), ('v2', 'v1'), ('v3', 'v2'), ('v4', 'v3'), ('v2', 'v5'), ('v5', 'v4'), ('v5', 'v6'), ('v6', 'v2')]\n",
    "g2 = nx.DiGraph(edges)\n",
    "adjacency_list = {node: [] for node in nodes}\n",
    "print(adjacency_list)\n",
    "for edge in edges:\n",
    "    source, target = edge\n",
    "    adjacency_list[source].append(target)\n",
    "print(adjacency_list)\n",
    "\n",
    "alpha = 0.85\n",
    "epsilon = 1e-6\n",
    "beta = [0.3, 0.2, 0.1, 0.1, 0.1, 0.4]\n",
    "# the concepts of calculate_pagerank comes from the documentation from networkx pagerank.\n",
    "def calculate_pagerank(pagerank, iteration=0):\n",
    "    new_pagerank = [0.0] * 6\n",
    "    for i in range(6):\n",
    "        _sum = 0\n",
    "        for j in range(6):\n",
    "            if nodes[j] in adjacency_list[nodes[i]]:\n",
    "                out_degree_j = len(adjacency_list[nodes[j]])\n",
    "                _sum += pagerank[j] / out_degree_j\n",
    "        \n",
    "        new_pagerank[i] = (1 - alpha) + alpha * _sum * beta[i]\n",
    "\n",
    "    if iteration > 0 and all(abs(new_pagerank[i] - pagerank[i]) < epsilon for i in range(6)):\n",
    "        #The function must have converged to a stationary point so we just return the new_pagerank\n",
    "        return new_pagerank\n",
    "    else:\n",
    "        #recursively call the function again since it has not fully converged yet.\n",
    "        return calculate_pagerank(new_pagerank, iteration + 1)\n",
    "normalize = sum(beta)\n",
    "beta = [value / normalize for value in beta]\n",
    "final_pagerank = calculate_pagerank(beta)\n",
    "\n",
    "\n",
    "print(\"PageRank Results:\")\n",
    "for i, score in enumerate(final_pagerank):\n",
    "    print(f\"{nodes[i]}: {score}\")\n",
    "beta_dict = {nodes[i]: beta[i] for i in range(len(nodes))}\n",
    "\n",
    "nx_pagerank = nx.pagerank(g2, alpha=alpha,dangling=beta_dict)\n",
    "print(\"\\nNetworkx PageRank Results:\")\n",
    "for node, score in nx_pagerank.items():\n",
    "    print(f\"{node}: {score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c73c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to implement my betweenness centrality algorithm: 0.00013379199663177133\n",
      "Time to implement networkx betweenness centrality algorithm: 0.00018833298236131668\n",
      "Node\tManual Betweenness\n",
      "v1\t0.02\n",
      "v2\t0.43\n",
      "v3\t0.12\n",
      "v4\t0.26\n",
      "v5\t0.11\n",
      "v6\t0.08\n",
      "Node\tNetworkX Betweenness\n",
      "v1\t 0.00\n",
      "v2\t 0.08\n",
      "v3\t 0.07\n",
      "v4\t 0.28\n",
      "v5\t 0.00\n",
      "v6\t 0.16\n"
     ]
    }
   ],
   "source": [
    "##################Question 3a######################\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "edges = [('v1', 'v2', 7), ('v1', 'v3', 8), ('v2', 'v3', 3), ('v2', 'v4', 2),\n",
    "         ('v3', 'v4', 1), ('v2', 'v5', 4), ('v4', 'v6', 1), ('v5', 'v6', 1)]\n",
    "\n",
    "G = nx.Graph()\n",
    "for edge in edges:\n",
    "    u, v, weight = edge\n",
    "    G.add_edge(u, v, weight=weight)\n",
    "# Implemented the brandes_betweenness_centrality algorithm.\n",
    "def brandes_betweenness_centrality(G):\n",
    "    betweenness = defaultdict(float)\n",
    "    for node in G.nodes():\n",
    "        stack, predecessors, sigma, distance = [], defaultdict(list), defaultdict(int), defaultdict(int)\n",
    "        sigma[node], distance[node], queue = 1, 0, [node]\n",
    "        while queue:\n",
    "            current_node = queue.pop(0)\n",
    "            stack.append(current_node)\n",
    "            for neighbor in G.neighbors(current_node):\n",
    "                if distance[neighbor] == 0:\n",
    "                    queue.append(neighbor)\n",
    "                    distance[neighbor] = distance[current_node] + 1\n",
    "                if distance[neighbor] == distance[current_node] + 1:\n",
    "                    sigma[neighbor] += sigma[current_node]\n",
    "                    predecessors[neighbor].append(current_node)\n",
    "\n",
    "        delta = defaultdict(float)\n",
    "        while stack:\n",
    "            current_node = stack.pop()\n",
    "            for predecessor in predecessors[current_node]:\n",
    "                delta[predecessor] += (sigma[predecessor] / sigma[current_node]) * (1 + delta[current_node])\n",
    "            if current_node != node:\n",
    "                betweenness[current_node] += delta[current_node]\n",
    "\n",
    "    return dict(betweenness)\n",
    "#Normalize data with the same equation displayed in the networkx documentation https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.betweenness_centrality.html\n",
    "def normalize(centrality_dict):\n",
    "    n = len(centrality_dict)\n",
    "    normalization_factor = 1 / ((n - 1) * (n - 2))\n",
    "    normalized_centrality = {node: value * normalization_factor for node, value in centrality_dict.items()}\n",
    "    return normalized_centrality\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "betweenness_centrality = brandes_betweenness_centrality(G)\n",
    "normalized_manual_betweenness = normalize(betweenness_centrality)\n",
    "end_time = time.perf_counter()\n",
    "print(\"Time to implement my betweenness centrality algorithm: {}\".format(end_time - start_time))\n",
    "start_time2 = time.perf_counter()\n",
    "betweenness_centrality_networkx = nx.betweenness_centrality(G, weight='weight', normalized=False)\n",
    "normalized_networkx_betweenness = normalize(betweenness_centrality_networkx)\n",
    "end_time2 = time.perf_counter()\n",
    "print(\"Time to implement networkx betweenness centrality algorithm: {}\".format(end_time2 - start_time2))\n",
    "\n",
    "print(\"Node\\tManual Betweenness\")\n",
    "for node in G.nodes():\n",
    "    print(f\"{node}\\t{normalized_manual_betweenness[node]:.2f}\")\n",
    "    \n",
    "print(\"Node\\tNetworkX Betweenness\")\n",
    "for node in G.nodes():\n",
    "    print(f\"{node}\\t {normalized_networkx_betweenness[node]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30f1d345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers with highest hubs:\n",
      "Paper ID: 9905111\n",
      "Out-Degree: 562\n",
      "----------------------\n",
      "Paper ID: 110055\n",
      "Out-Degree: 302\n",
      "----------------------\n",
      "Paper ID: 7170\n",
      "Out-Degree: 263\n",
      "----------------------\n",
      "\n",
      "Papers with highest authorities:\n",
      "Paper ID: 9711200\n",
      "In-Degree: 2414\n",
      "----------------------\n",
      "Paper ID: 9802150\n",
      "In-Degree: 1775\n",
      "----------------------\n",
      "Paper ID: 9802109\n",
      "In-Degree: 1641\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file = open(\"Cit-HepTh.txt\", \"r\")\n",
    "lines = file.readlines()\n",
    "file.close()\n",
    "\n",
    "g4 = nx.DiGraph()\n",
    "\n",
    "for line in lines[4:]:\n",
    "    v, u = line.strip().split(\"\\t\")\n",
    "    g4.add_edge(int(v), int(u))\n",
    "\n",
    "hub, auth = nx.hits(g4)\n",
    "\n",
    "hubs = sorted(hub, key=hub.get, reverse=True)[:3]\n",
    "auths = sorted(auth, key=auth.get, reverse=True)[:3]\n",
    "\n",
    "in_degrees = dict(g4.in_degree())\n",
    "out_degrees = dict(g4.out_degree())\n",
    "\n",
    "print(\"Papers with highest hubs:\")\n",
    "for paper_id in hubs:\n",
    "    print(\"Paper ID:\", paper_id)\n",
    "    print(\"Out-Degree:\", out_degrees[paper_id])\n",
    "    print(\"----------------------\")\n",
    "\n",
    "print(\"\\nPapers with highest authorities:\")\n",
    "for paper_id in auths:\n",
    "    print(\"Paper ID:\", paper_id)\n",
    "    print(\"In-Degree:\", in_degrees[paper_id])\n",
    "    print(\"----------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
